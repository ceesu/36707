---
title: "Health exams in Vietnam Data Analysis Report"
author: "Qiao Su"
date: "19/11/2019"
output:
  pdf_document: default
  html_document:
    fig_caption: yes
    highlight: tango
bibliography: report3.bib
---

```{r setup, include=FALSE}
#http://rosmarus.refsmmat.com/datasets/datasets/vietnam-health/

# libraries
library(AER)
library(stargazer)
library(tidyverse)
library(lattice)
library(dagitty)
library(reshape2)
library(grid)
library(gridExtra)
library("ggpubr")
library(knitr)
library(bestglm)
library(cowplot)

opts_knit$set(eval.after = 'fig.cap')
knitr::opts_chunk$set(echo = FALSE, width.cutoff=60, fig.pos = 'H')
set.seed(1234)

mod_stargazer <- function(...){
  output <- capture.output(stargazer(...))
  # The first three lines are the ones we want to remove...
  output <- output[4:length(output)]
  # cat out the results - this is essentially just what stargazer does too
  cat(paste(output, collapse = "\n"), "\n")
}

# data
data <- read.csv("../data/vietnam-health.csv",
                     sep = ",", 
                    header = T)


# some should be numeric
data$height <- as.numeric(as.character(data$height))
data$weight <- as.numeric(as.character(data$weight))
data$BMI <- as.numeric(gsub(",","\\.",data$BMI))
# data$Tangibles <- as.numeric(data$Tangibles)
# data$Reliability <- as.numeric(data$Reliability)
# data$Respon<- as.numeric(data$Respon)
# data$Assurance<- as.numeric(data$Assurance)
# data$Empathy<- as.numeric(data$Empathy)

# PROPER CONVERSION OF THE RATINGS
data[,c(33:37,44:48)] <-lapply(data[,c(33:37,44:48)], as.character)
data[,c(33:37,44:48)] <-lapply(data[,c(33:37,44:48)], as.numeric)
data[,c(12:18)]<-lapply(data[,c(12:18)], as.factor)

#test <- data$BMI/(data$weight/((data$height/100)^2))
head(data[!complete.cases(data),])
colnames(data)[colSums(is.na(data)) > 0]
# > colnames(data)[colSums(is.na(data)) > 0]
#  [1] "height"      "weight"      "Tangibles"   "Reliability" "Respon"      "Assurance"  
#  [7] "Empathy"     "SuffInfo"    "AttractInfo" "ImpressInfo" "PopularInfo"

# trim BMI

####### GROUP THE VARIABLES
summary(data)

####### CLEANED DATA
dat <- data %>% select(-c(height, weight)) %>% 
  filter(between(date, 20160810, 20161031)) %>% 
  filter(between(BMI, 0, 35)) %>%
  filter(between(Age, 0, 50)) 
demo_vars <- colnames(dat)[c(2:8,47)]
health_vars <- colnames(dat)[c(9:12,21:28,45:46)]
check_vars <- colnames(dat)[c(13:20, 29:44)]


```

## Executive Summary

Medical care for serious diseases can be very expensive, and in countries without estab-
lished socialized medical systems it can impose serious hardships on patients. Ideally, patients would get regular check-ups (or “general health examinations,” GHEs) so thatserious conditions could be detected and treated early, before they cause serious prob-
lems. This would save money and improve public health.

However, there are many possible obstacles to getting everyone to go to regular check-
ups. They might be too expensive, or too difficult to schedule; some people may not trust

doctors or believe that check-ups have any value; or some people may have had bad expe-
riences when they previously tried to get check-ups.

Public health researchers in Vietnam wanted to explore these reasons and determine

what obstacles prevented widespread use of regular check-ups. They conducted an inter-
view survey in Hanoi and Hung Yen, Vietnam, by traveling to “secondary schools, hospi-
tals, companies, government agencies and randomly selected households in Hanoi” and

interviewing people in person for about 10–15 minutes. This dataset contains the raw data
from that survey, totaling 2,068 valid responses.

Table 2 describes some of the categorical variables in the dataset. Over half the sample (n= 1,059, 51.21%) had had a GHE less than a year ago. One of the most common reasons given for hesitating to have a GHE was that they are waste of time; nearly 52% of participants who were reluctant to attend GHEs mentioned this as a reason. Amongst those who were prepared to attend GHEs, the main reason given

If they experienced symptoms of ill-health the majority of participants would choose to go to a clinic
(43.04%). Most respondents (86.32%) believed that a GHE should cost less than 2 million VND, indicating that reasonable pricing is a big concern for people in relation to periodic GHEs

If a healthcare app indicated symptoms of disease then 39.41% of participants would be willing to have a GHE.

## Introduction

In addition, a number of people remain skeptical about the value of health examination (GHE) programmes, either finding them costly and without benefit7–9 or questioning their quality.

The dataset includes three categories of variables about the participants. The first category are demographics such as BMI, age, education and sex. The second category quantifies their attitude towards health such as whether they can basic medical equipment, and how much time the respondent spends on sports and physical exercise. The last category quantifies their attitudes relating directly to the GHEs such as their perceived ability of examiner and the percieved attractiveness of information they received in check-ups.

## Methods

### Removal of outliers and missing data

After importing the data, we found there was 90 cases with missing data out of the 2068 participants. The variables with missing data included numeric variables only: height, weight and the ratings of GHEs e.g. percieved timeliness of the checkup. We first discarded height and weight since these two correspond fully to BMI (see EDA). There seemed to be a possibility that the remainder missing cases were informative missing data, since the participants had answered everything else. Therefore we kept the other observations that had missing data.

We also looked for outliers in the data among the remaining variables. Only the Age and BMI directly inform us about the patient's health so outliers in these variables are very important. Additionally, we removed outliers in the date to restrict participants from September to October 2016. This left 1941 responses.  

## Exploratory Data Analysis 

We may hypothesize that the respondent's general health is inversely related to their incidence of disease. Furthermore their perceptions of GHEs may be approximately correlated with what value they have derived from the procedures in improving their health. Lastly the number of GHEs brings up the cost of healthcare. 

```{r causal, fig.width=4, fig.height=1.5, echo=FALSE, fig.cap="\\label{fig:cause} Causal diagram illustrates hypothesized relationships between checkups, disease and cost of public healthcare."}

g <- dagitty('dag {
    health [pos="0,0.75"]
    incidence_disease [pos="1,0.5"]
    perception_of_GHE [pos="1,1"]
    frequency_of_GHE [pos="0.5,0.75"]
    health_insurance [pos="0,0.5"]
    health -> incidence_disease
    health_insurance -> frequency_of_GHE<-health 
    frequency_of_GHE -> perception_of_GHE
}')

plot(g)
```

### Univariate variable distributions
Data were collected in 2016 from participants from 13 to 83 years of age, on 31 separate dates in the year 2016. As seen in Figure \ref{fig:trim} A-C, there are outlier values in the variables date, age and BMI. There are outlier dates in Figure \ref{fig:trim} A which may be typos and fall outside of real dates e.g. '20169828'. Therefore we trimmed the few outlier dates which fall outside of September and October 2016.  For age and BMI, we can see in Figure \ref{fig:trim}B-C that the data are upward skewed by a few outliers. We therefore removed data with age greater than 50 and BMI greater than 35.

BMI is an important indication of fitness and calculated as weight (kg) / [height (m)]^2. When we calculated the BMI from the height and weight we found that the quantities corresponded exactly, as seen in Figure \ref{fig:trim} D. Therefore since BMI is more indicative of health, we discarded height and weight variables.

```{r bmi, include=FALSE, fig.width=5, fig.height=4, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:bmi} BMI corresponds to height and weight."}
test <- data$BMI/(data$weight/((data$height/100)^2))
outs <- data[test > 1.2,] #NA
outs <- data[test < 0.5,]
p1 <-ggplot(data, aes(x= BMI, y = weight/((height/100.0)**2)))+
  geom_point()
p4 <-ggplot(data, aes(y= BMI))+
  geom_boxplot() #+theme_hw
boxplot(test)
summary(test)
boxplot(data$height)
```


```{r trim, fig.width=5, fig.height=3, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:trim} A-C) Distributions of important demographic variables in the raw data show outliers. We trimmed the outliers in the date, age and BMI. D) We can also see BMI is perfectly calculated from height and weight."}
theme_hw <- theme(plot.title = element_text(hjust = 0.5),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()
       # panel.grid.major =   element_line(colour = "gray",size=0.5)
  )

p1 <-ggplot(data, aes(x= BMI, y = weight/((height/100.0)**2)))+
  geom_point()#+theme_hw #+ ylab("Testosterone in pg/mL")
# boxplot(test)
p2 <-ggplot(data, aes(y=Age))+
  geom_boxplot() +theme_hw#+ ylab("Log(Testosterone in pg/mL)")
p3 <-ggplot(data, aes(y=date))+
  geom_boxplot() +theme_hw#+ ylab("Cortisol in nMol/L")
p4 <-ggplot(data, aes(y= BMI))+
  geom_boxplot() +theme_hw
# summary(test)
plot_grid(p3, p2,p4,p1,  
             nrow=1, labels = c('A', 'B', 'C', 'D'), label_size = 12)

```

### Pairwise distributions

We checked the correlation among the numeric variables of the filtered dataset in Figure \ref{fig:pairs}. We observed that there doesn't appear to be collinearity among the numeric variables. Furthermore, age and BMI have a reasonable correlation. Additionally, we found that the ratings naturally grouped by correlation into responses concerning the quality of GHEs (Tangibles, percieved quality of tangible equipment and personnel to Empathy, percieved empathy of the staff) and about the type of information they recieve during GHEs (SuffInfo, rating of the sufficiency, to Popular info, rating of the popularity of the information). 

```{r eda, fig.width=10, fig.height=10, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:pairs} Pairwise correlations of numeric variables including their Pearson correlation coefficient."}
# check relationships of all variables of interest
#vars <- colnames(data)[c(2:13)]
#cor(team_dat)
#pairs(team_dat[vars], pch = 19,  lower.panel=NULL)
library("PerformanceAnalytics")

vars <- unlist(lapply(dat, is.numeric))  
chart.Correlation(dat[vars], pch=19)
#summary(data)
#library(GGally)
#ggpairs(data[,quant_vars])
```

## Introduction

## Q1. 

**Overall, how do people rate the attractiveness, impressiveness, sufficiency, and popularity of information they receive in checkups? Give us some summaries of these variables, as well as variables like assurance, reliability, and empathy that tell us how well our doctors and nurses are doing, so we know how to improve.**

The distributions across the diagonal in Figure \ref{fig:pairs} show summaries of the attractiveness (AttractInfo), impressiveness (ImpressInfo), sufficiency (SuffInfo), and popularity (PopularInfo) of information they recieve. The average rating about the type of information recieved in GHEs is significantly correlated and tends to score a 3 on the 5-point scale. There is also clustering of the ratings giving perceptions of the quality of periodic GHE sessions which includes the tangibles (Tangibles), assurance (Assurance), reliability (Reliability), responsibility (Respon), and empathy (Empathy) variables. These ratings are higher on average. 


```{r q1, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}

mod <- glm(views ~ posts + authors + offset(log(startdate)), 
           family =quasipoisson(log), 
           data = dat)
par(mfrow=c(2,2))
plot(mod)
```

## Q2. 

**What factors make a person less likely to get check-up every twelve months? Find the most important factors that could help us design our advertising, and give us some measure of how important they are.**

Here we want to predict the variable RecPerExam (the time since the respondent got an unprompted checkup). RecPerExam has four levels, among them is 'unknown'. We first trimmed the cases that are unknown leaving 1467 cases. Since the response variable is not continuous we used a binomial glm to model. 

We performed variable selection among all of the variables available (except the participant id) in order to exclude variables without large effects. First we picked how many terms we should have in the best predictive linear model by using 10-fold cross validation with best subsets regression and plotted the mean squared error in Figure \ref{fig:cv}. We used the bestglm package to help fit the glm to the training data. This analysis shows validation error is lowest around 8 terms.

Next we fit the model to RecPerExam with the top XXX variables. 

```{r cv, echo=FALSE, message=FALSE, warning= FALSE, fig.cap="\\label{fig:cv} Cross validation error for each number of predictors"}
# http://www.science.smith.edu/~jcrouser/SDS293/labs/lab9-r.html

dat_q2 <- dat %>% filter(RecPerExam != "unknow") %>% droplevels()
library(leaps)
set.seed(12)
folds=sample(rep(1:10,length=nrow(dat_q2)))

predict.regsubsets=function(object,newdata,id,...){
  form=as.formula(object$call[[2]])
  mat=model.matrix(form,newdata)
  coefi=coef(object,id=id) # extract the 'top' coefficients according to best subsets
  mat[,names(coefi)]%*%coefi
}

vars <- colnames(dat_q2)[2:48]
cv.errors=matrix(NA,10,length(vars))
#### ITERATE OVER K FOLDS
for(k in 1:10){
  # best fit on the train data
  # nvmax is maximum size of subsets to examine
  # it may take too long to do exhaustive search
  best.fit=regsubsets(RecPerExam ~ ., data=dat_q2[folds!=k, vars],nvmax=length(vars),
                      method = "forward") 
                      #method = "exhaustive") 
  
  #### ITERATE OVER EACH OF THE I NUMBER OF PREDICTORS
  for(i in 1:40){
    lbw.for.bestglm <-
    bestglm(Xy = lbw.for.bestglm,
            family = gaussian,
            IC = "AIC",                 
            method = "exhaustive")
    # get the fit on 'i' variables
    pred=predict.regsubsets(best.fit,dat_q2[folds==k,vars], id=i)
    cv.errors[k,i]=mean((as.numeric(dat_q2$RecPerExam[folds==k])-pred)^2)
    
  }
}

# Take the mean of over all folds for each model size
mean_cv_errors = apply(cv.errors, 2, mean)

# Find the model size with the smallest cross-validation error
min = which.min(mean_cv_errors)

# Plot the cross-validation error for each model size, highlight the min
plot(mean_cv_errors, type='b', xlab = "Number of predictors",
     ylab = "Mean cross validation error (percent)")
points(min, mean_cv_errors[min][1], col = "red", cex = 2, pch = 20)

```

## Q3. 

**Can we predict which people would be easiest to convince? That is, some people might be on the edge, and would get an exam with a little extra push; some people are very determined and would not get an exam no matter how hard you try. Using a classifier, can you find the patients who haven’t gotten an exam but are most like other patients who have? Be sure to tell us how well your classifier works, so we know whether this is reliable.**

The variable which best 

```{r q3, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}
# > which(rownames(dat) == 8346,)
# [1] 7519

#temp <- dat[-7519,]
# mod <- glm(views ~ posts + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
mod <- glm(views ~ posts + authors + offset(log(startdate)), 
           family =quasipoisson(log), 
           data = dat)
par(mfrow=c(2,2))
plot(mod)
```




```{r classifier, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}
# > which(rownames(dat) == 8346,)
# [1] 7519

#temp <- dat[-7519,]
# mod <- glm(views ~ posts + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
mod <- glm(views ~ posts + authors + offset(log(startdate)), 
           family =quasipoisson(log), 
           data = dat)
par(mfrow=c(2,2))
plot(mod)
```
## Conclusion

## Bibliography
