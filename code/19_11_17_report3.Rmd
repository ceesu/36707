---
title: "Health exams in Vietnam Data Analysis Report"
author: "Cathy Su"
date: "19/11/2019"
output:
  pdf_document: default
  html_document:
    fig_caption: yes
    highlight: tango
bibliography: report3.bib
---

```{r setup, include=FALSE}
#http://rosmarus.refsmmat.com/datasets/datasets/vietnam-health/

# libraries
library(AER)
library(stargazer)
library(tidyverse)
library(lattice)
library(dagitty)
library(reshape2)
library(grid)
library(gridExtra)
library("ggpubr")
library(knitr)
library(bestglm)

opts_knit$set(eval.after = 'fig.cap')
knitr::opts_chunk$set(echo = FALSE, width.cutoff=60, fig.pos = 'H')
set.seed(1234)

mod_stargazer <- function(...){
  output <- capture.output(stargazer(...))
  # The first three lines are the ones we want to remove...
  output <- output[4:length(output)]
  # cat out the results - this is essentially just what stargazer does too
  cat(paste(output, collapse = "\n"), "\n")
}

# data
data <- read.csv("../data/vietnam-health.csv",
                     sep = ",", 
                    header = T)
# some should be numeric
data$height <- as.numeric(data$height)
data$weight <- as.numeric(data$weight)
data$BMI <- as.numeric(data$BMI)
data$Tangibles <- as.numeric(data$Tangibles)
data$Reliability <- as.numeric(data$Reliability)
data$Respon<- as.numeric(data$Respon)
data$Assurance<- as.numeric(data$Assurance)
data$Empathy<- as.numeric(data$Empathy)
data[,c(44:47)] <-lapply(data[,c(44:47)], as.numeric)

# trim BMI
test <- data$BMI/(data$weight/((data$height/100)^2))

####### NEW VARIABLES
summary(data)

####### CLEANED DATA

dat <- data %>% select(-c(height, weight, id, Jobstt, SuitExer))


```

## Executive Summary

Medical care for serious diseases can be very expensive, and in countries without estab-
lished socialized medical systems it can impose serious hardships on patients. Ideally, patients would get regular check-ups (or “general health examinations,” GHEs) so thatserious conditions could be detected and treated early, before they cause serious prob-
lems. This would save money and improve public health.

However, there are many possible obstacles to getting everyone to go to regular check-
ups. They might be too expensive, or too difficult to schedule; some people may not trust

doctors or believe that check-ups have any value; or some people may have had bad expe-
riences when they previously tried to get check-ups.

Public health researchers in Vietnam wanted to explore these reasons and determine

what obstacles prevented widespread use of regular check-ups. They conducted an inter-
view survey in Hanoi and Hung Yen, Vietnam, by traveling to “secondary schools, hospi-
tals, companies, government agencies and randomly selected households in Hanoi” and

interviewing people in person for about 10–15 minutes. This dataset contains the raw data
from that survey, totaling 2,068 valid responses.


## Introduction

In addition, a number of people remain skeptical about the value of health examination (GHE) programmes, either finding them costly and without benefit7–9 or questioning their quality.

The dataset includes three categories of variables about the participants. The first category are demographics such as BMI, age, education and sex. The second category quantifies their attitude towards health such as whether they can basic medical equipment, and how much time the respondent spends on sports and physical exercise. The last category quantifies their attitudes relating directly to the GHEs such as their perceived ability of examiner and the percieved attractiveness of information they received in check-ups.

## Methods

### Removal of outliers and missing data

We discarded the following variables:
* Jobstt: the job status response categories were uninformative (stable, unstable, student, retired, homemaker, or other). In particular, it's hard to even tell if the respondent is employed.
* height and weight: these two can be inferred from BMI. Outliers discussed in EDA were thrown out.
* SuitExer: half of the respondents answered "unknown" for this question, and for the portion that had an answer, no units were given.

### Calculation of additional variables 


## Exploratory Data Analysis 

In terms of demographics, data were all collected in 2016 from participants from 13 to 83 years of age. 

### Causal diagram 

We may hypothesize that the respondent's general health is inversely related to their incidence of disease. Furthermore their perceptions of GHEs may be approximately correlated with what value they have derived from the procedures in improving their health. Lastly the number of GHEs brings up the cost of healthcare. Therefore, we may believe that if the respondent 

```{r causal, fig.width=6, fig.height=1.5, echo=FALSE, fig.cap="\\label{fig:cause} Causal diagram illustrates hypothesized relationships between checkups, disease and cost of public healthcare."}

g <- dagitty('dag {
    state [pos="0,1"]
    authors [pos="1,0.5"]
    proportion_deleted [pos="1,1"]
    topic_category [pos="2,0.5"]
    
    startdate ->posts <- topic_category -> authors-> posts-> state
    posts ->views <-startdate
}')

plot(g)
```

### Univariate variable distributions

We found outliers in the following variables which were removed.
* BMI is calculated as weight (kg) / [height (m)]^2. However when we calculated the BMI from the height and weight we found that the quantities were not always linearly related.

We found that there was a missing r for the following variables:

* RecExam, RecPerExam: Time since the respondent last visited a doctor with symptoms of a disease or for a check-up.
* CHPerc: Respondent's general opinion of public health. This included 260 'unknown' responses. 

```{r}
theme_hw <- theme(plot.title = element_text(hjust = 0.5),
        #axis.text.x=element_blank(),
        axis.ticks.x=element_blank()
       # panel.grid.major =   element_line(colour = "gray",size=0.5)
  )

p1 <-ggplot(data, aes(x= BMI, y = weight/((height/100.0)**2)))+
  geom_point()#+theme_hw #+ ylab("Testosterone in pg/mL")
# boxplot(test)
p2 <-ggplot(data, aes(y=as.numeric(SuitExer)))+
  geom_boxplot()#+ ylab("Log(Testosterone in pg/mL)")
p3 <-ggplot(data, aes(x=as.factor(pinned)))+
  geom_bar()+theme_hw #+ ylab("Cortisol in nMol/L")
p4 <-ggplot(data, aes(x=as.factor(author_banned)))+
  geom_bar()+theme_hw #+ ylab("Log(cortisol in nMol/L)")
# summary(test)
grid.arrange(p1, 
             ncol = 4)

```

### Pairwise distributions

We checked the corrrelation among the numeric variables in Figure \ref{fig:pairs}. 

```{r eda, fig.width=10, fig.height=10, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:pairs} Pairwise correlations of numeric variables including their Pearson correlation coefficient."}
# check relationships of all variables of interest
#vars <- colnames(data)[c(2:13)]
#cor(team_dat)
#pairs(team_dat[vars], pch = 19,  lower.panel=NULL)
library("PerformanceAnalytics")

vars <- unlist(lapply(dat, is.numeric))  
chart.Correlation(dat[vars], pch=19)
#summary(data)
#library(GGally)
#ggpairs(data[,quant_vars])
```

## Introduction

## Q1. 

Overall, how do people rate the attractiveness, impressiveness, sufficiency, and pop-
ularity of information they receive in checkups? Give us some summaries of these variables, as well as variables like assurance, reliability, and empathy that tell us how well our doctors and nurses are doing, so we know how to improve.

```{r q1, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}
# > which(rownames(dat) == 8346,)
# [1] 7519

#temp <- dat[-7519,]
# mod <- glm(views ~ posts + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
mod <- glm(views ~ posts + authors + offset(log(startdate)), 
           family =quasipoisson(log), 
           data = dat)
par(mfrow=c(2,2))
plot(mod)
```

## Q2. 

What factors make a person less likely to get check-up every twelve months? Find
the most important factors that could help us design our advertising, and give us
some measure of how important they are.

### Selecting the variables with non-negligible effect

Out of the variables that we had considered in Figure \ref{fig:pairs}, to build models we first performed variable selection to exclude those without large effects. We included the interaction terms between diversity score and each of the hormones, which are interpretable interaction terms that we need to consider to answer the substantive questions. 
First we picked how many terms we should have in the best predictive linear model by using 10-fold cross validation and plotted the mean squared error in Figure \ref{fig:cv}. This analysis shows validation error is lowest around 8 terms.

```{r cv, echo=FALSE, message=FALSE, warning= FALSE, fig.cap="\\label{fig:cv} Cross validation error for each number of predictors"}

library(leaps)
set.seed(12)
folds=sample(rep(1:10,length=nrow(team_dat)))

predict.regsubsets=function(object,newdata,id,...){
  form=as.formula(object$call[[2]])
  mat=model.matrix(form,newdata)
  coefi=coef(object,id=id)
  mat[,names(coefi)]%*%coefi
}

vars <-c(allvars)
cv.errors=matrix(NA,10,11)
for(k in 1:10){
  # best fit on the train data
  best.fit=regsubsets(final.performance~. + avg.log.testosterone:diversity.score + diversity.score:avg.log.cortisol, data=team_dat[folds!=k, vars],nvmax=40,method="exhaustive")
  # performance on the test data
  for(i in 1:10){
    pred=predict(best.fit,team_dat[folds==k,vars],id=i)
    cv.errors[k,i]=mean((team_dat$final.performance[folds==k]-pred)^2)
  }
}

# Take the mean of over all folds for each model size
mean_cv_errors = apply(cv.errors, 2, mean)

# Find the model size with the smallest cross-validation error
min = which.min(mean_cv_errors)

# Plot the cross-validation error for each model size, highlight the min
plot(mean_cv_errors, type='b', xlab = "Number of predictors",
     ylab = "Mean cross validation error (percent)")
points(min, mean_cv_errors[min][1], col = "red", cex = 2, pch = 20)

```

## Q3. 

**Can we predict which people would be easiest to convince? That is, some people
might be on the edge, and would get an exam with a little extra push; some people
are very determined and would not get an exam no matter how hard you try. Using
a classifier, can you find the patients who haven’t gotten an exam but are most like
other patients who have? Be sure to tell us how well your classifier works, so we
know whether this is reliable.**

In this case:

The intercept= -9.79394 which is interpreted as the log odds of a student with a math score of zero being in an honors class.

The coefficient for math= 0.15634 which is interpreted as the expected change in log odds for a one-unit increase in the math score. The odds ratio can be calculated by exponentiating this value to get 1.16922 which means we expect to see about 17% increase in the odds of being in an honors class, for a one-unit increase in math score



```{r q3, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}
# > which(rownames(dat) == 8346,)
# [1] 7519

#temp <- dat[-7519,]
# mod <- glm(views ~ posts + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
mod <- glm(views ~ posts + authors + offset(log(startdate)), 
           family =quasipoisson(log), 
           data = dat)
par(mfrow=c(2,2))
plot(mod)
```




```{r classifier, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}
# > which(rownames(dat) == 8346,)
# [1] 7519

#temp <- dat[-7519,]
# mod <- glm(views ~ posts + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
mod <- glm(views ~ posts + authors + offset(log(startdate)), 
           family =quasipoisson(log), 
           data = dat)
par(mfrow=c(2,2))
plot(mod)
```
## Conclusion

## Bibliography
