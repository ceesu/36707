---
title: "Health exams in Vietnam Data Analysis Report"
author: "Qiao Su"
date: "19/11/2019"
output:
  pdf_document: default
  html_document:
    fig_caption: yes
    highlight: tango
bibliography: report3.bib
---

```{r setup, include=FALSE}
#http://rosmarus.refsmmat.com/datasets/datasets/vietnam-health/

# libraries
library(AER)
library(stargazer)
library(tidyverse)
library(lattice)
library(dagitty)
library(reshape2)
library(grid)
library(gridExtra)
library("ggpubr")
library(knitr)
library(bestglm)
library(cowplot)

opts_knit$set(eval.after = 'fig.cap')
knitr::opts_chunk$set(echo = FALSE, width.cutoff=60, fig.pos = 'H')
set.seed(1234)

mod_stargazer <- function(...){
  output <- capture.output(stargazer(...))
  # The first three lines are the ones we want to remove...
  output <- output[4:length(output)]
  # cat out the results - this is essentially just what stargazer does too
  cat(paste(output, collapse = "\n"), "\n")
}

# data
data <- read.csv("../data/vietnam-health.csv",
                     sep = ",", 
                    header = T)


# some should be numeric
data$height <- as.numeric(as.character(data$height))
data$weight <- as.numeric(as.character(data$weight))
data$BMI <- as.numeric(gsub(",","\\.",data$BMI))
# data$Tangibles <- as.numeric(data$Tangibles)
# data$Reliability <- as.numeric(data$Reliability)
# data$Respon<- as.numeric(data$Respon)
# data$Assurance<- as.numeric(data$Assurance)
# data$Empathy<- as.numeric(data$Empathy)

# PROPER CONVERSION OF THE RATINGS
data[,c(33:37,44:48)] <-lapply(data[,c(33:37,44:48)], as.character)
data[,c(33:37,44:48)] <-lapply(data[,c(33:37,44:48)], as.numeric)
data[,c(12:18)]<-lapply(data[,c(12:18)], as.factor)

#test <- data$BMI/(data$weight/((data$height/100)^2))
head(data[!complete.cases(data),])
colnames(data)[colSums(is.na(data)) > 0]
# > colnames(data)[colSums(is.na(data)) > 0]
#  [1] "height"      "weight"      "Tangibles"   "Reliability" "Respon"      "Assurance"  
#  [7] "Empathy"     "SuffInfo"    "AttractInfo" "ImpressInfo" "PopularInfo"

# trim BMI

####### GROUP THE VARIABLES
summary(data)

####### CLEANED DATA
dat <- data %>% select(-c(height, weight)) %>% 
  filter(between(date, 20160810, 20161031)) %>% 
  filter(between(BMI, 0, 35)) %>%
  filter(between(Age, 0, 50)) 
demo_vars <- colnames(dat)[c(2:8,47)]
health_vars <- colnames(dat)[c(9:12,21:28,45:46)]
check_vars <- colnames(dat)[c(13:20, 29:44)]


```

## Executive Summary

Medical care for serious diseases can be very expensive, and in countries without estab-
lished socialized medical systems it can impose serious hardships on patients. Ideally, patients would get regular check-ups (or “general health examinations,” GHEs) so thatserious conditions could be detected and treated early, before they cause serious prob-
lems. This would save money and improve public health.

However, there are many possible obstacles to getting everyone to go to regular check-
ups. They might be too expensive, or too difficult to schedule; some people may not trust

doctors or believe that check-ups have any value; or some people may have had bad expe-
riences when they previously tried to get check-ups.

Public health researchers in Vietnam wanted to explore these reasons and determine

what obstacles prevented widespread use of regular check-ups. They conducted an inter-
view survey in Hanoi and Hung Yen, Vietnam, by traveling to “secondary schools, hospi-
tals, companies, government agencies and randomly selected households in Hanoi” and

interviewing people in person for about 10–15 minutes. This dataset contains the raw data
from that survey, totaling 2,068 valid responses.

Table 2 describes some of the categorical variables in the dataset. Over half the sample (n= 1,059, 51.21%) had had a GHE less than a year ago. One of the most common reasons given for hesitating to have a GHE was that they are waste of time; nearly 52% of participants who were reluctant to attend GHEs mentioned this as a reason. Amongst those who were prepared to attend GHEs, the main reason given

If they experienced symptoms of ill-health the majority of participants would choose to go to a clinic
(43.04%). Most respondents (86.32%) believed that a GHE should cost less than 2 million VND, indicating that reasonable pricing is a big concern for people in relation to periodic GHEs

If a healthcare app indicated symptoms of disease then 39.41% of participants would be willing to have a GHE.

## Introduction

In addition, a number of people remain skeptical about the value of health examination (GHE) programmes, either finding them costly and without benefit7–9 or questioning their quality.

The dataset includes three categories of variables about the participants. The first category are demographics such as BMI, age, education and sex. The second category quantifies their attitude towards health such as whether they can basic medical equipment, and how much time the respondent spends on sports and physical exercise. The last category quantifies their attitudes relating directly to the GHEs such as their perceived ability of examiner and the percieved attractiveness of information they received in check-ups.

## Methods

### Removal of outliers and missing data

After importing the data, we found there was 90 cases with missing data out of the 2068 participants. The variables with missing data included numeric variables only: height, weight and the ratings of GHEs e.g. percieved timeliness of the checkup. We first discarded height and weight since these two correspond fully to BMI (see EDA). There seemed to be a possibility that the remainder missing cases were informative missing data, since the participants had answered everything else. Therefore we kept the other observations that had missing data.

We also looked for outliers in the data among the remaining variables. Only the Age and BMI directly inform us about the patient's health so outliers in these variables are very important. Additionally, we removed outliers in the date to restrict participants from September to October 2016. This left 1941 responses.  

## Exploratory Data Analysis 

We may hypothesize that the respondent's general health is inversely related to their incidence of disease. Furthermore their perceptions of GHEs may be approximately correlated with what value they have derived from the procedures in improving their health. Lastly the number of GHEs brings up the cost of healthcare. 

```{r causal, fig.width=4, fig.height=1.5, echo=FALSE, fig.cap="\\label{fig:cause} Causal diagram illustrates hypothesized relationships between checkups, disease and cost of public healthcare."}

g <- dagitty('dag {
    health [pos="0,0.75"]
    incidence_disease [pos="1,0.5"]
    perception_of_GHE [pos="1,1"]
    frequency_of_GHE [pos="0.5,0.75"]
    health_insurance [pos="0,0.5"]
    health -> incidence_disease
    health_insurance -> frequency_of_GHE<-health 
    frequency_of_GHE -> perception_of_GHE
}')

plot(g)
```

### Univariate variable distributions
Data were collected in 2016 from participants from 13 to 83 years of age, on 31 separate dates in the year 2016. As seen in Figure \ref{fig:trim} A-C, there are outlier values in the variables date, age and BMI. There are outlier dates in Figure \ref{fig:trim} A which may be typos and fall outside of real dates e.g. '20169828'. Therefore we trimmed the few outlier dates which fall outside of September and October 2016.  For age and BMI, we can see in Figure \ref{fig:trim}B-C that the data are upward skewed by a few outliers. We therefore removed data with age greater than 50 and BMI greater than 35.

BMI is an important indication of fitness and calculated as weight (kg) / [height (m)]^2. When we calculated the BMI from the height and weight we found that the quantities corresponded exactly, as seen in Figure \ref{fig:trim} D. Therefore since BMI is more indicative of health, we discarded height and weight variables.

```{r bmi, include=FALSE, fig.width=5, fig.height=4, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:bmi} BMI corresponds to height and weight."}
test <- data$BMI/(data$weight/((data$height/100)^2))
outs <- data[test > 1.2,] #NA
outs <- data[test < 0.5,]
p1 <-ggplot(data, aes(x= BMI, y = weight/((height/100.0)**2)))+
  geom_point()
p4 <-ggplot(data, aes(y= BMI))+
  geom_boxplot() #+theme_hw
boxplot(test)
summary(test)
boxplot(data$height)
```


```{r trim, fig.width=8, fig.height=4, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:trim} A-C) Distributions of important demographic variables in the raw data show outliers. We trimmed the outliers in the date, age and BMI. D) We can see BMI is corresponding well to BMI calculated from height and weight."}
theme_hw <- theme(plot.title = element_text(hjust = 0.5),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()
       # panel.grid.major =   element_line(colour = "gray",size=0.5)
  )

p1 <-ggplot(data, aes(x= BMI, y = weight/((height/100.0)**2)))+
  geom_point()#+theme_hw #+ ylab("Testosterone in pg/mL")
# boxplot(test)
p2 <-ggplot(data, aes(y=Age))+
  geom_boxplot() +theme_hw#+ ylab("Log(Testosterone in pg/mL)")
p3 <-ggplot(data, aes(y=date))+
  geom_boxplot() +theme_hw#+ ylab("Cortisol in nMol/L")
p4 <-ggplot(data, aes(y= BMI))+
  geom_boxplot() +theme_hw
# summary(test)
plot_grid(p3, p2,p4,p1,  
             nrow=1, labels = c('A', 'B', 'C', 'D'), label_size = 12)

```

### Pairwise distributions

We checked the correlation among the numeric variables of the filtered dataset in Figure \ref{fig:pairs}. We observed that there doesn't appear to be collinearity among the numeric variables. Furthermore, age and BMI have a reasonable correlation. Additionally, we found that the ratings naturally grouped by correlation into responses concerning the quality of GHEs (Tangibles, percieved quality of tangible equipment and personnel to Empathy, percieved empathy of the staff) and about the type of information they recieve during GHEs (SuffInfo, rating of the sufficiency, to Popular info, rating of the popularity of the information). 

```{r eda, fig.width=10, fig.height=10, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:pairs} Pairwise correlations of numeric variables including their Pearson correlation coefficient."}
# check relationships of all variables of interest
#vars <- colnames(data)[c(2:13)]
#cor(team_dat)
#pairs(team_dat[vars], pch = 19,  lower.panel=NULL)
library("PerformanceAnalytics")

vars <- unlist(lapply(dat, is.numeric))  
chart.Correlation(dat[vars], pch=19)
#summary(data)
#library(GGally)
#ggpairs(data[,quant_vars])
```

## Introduction

## Q1. 

**Overall, how do people rate the attractiveness, impressiveness, sufficiency, and popularity of information they receive in checkups? Give us some summaries of these variables, as well as variables like assurance, reliability, and empathy that tell us how well our doctors and nurses are doing, so we know how to improve.**

In order to summarize how respondents felt about checkups, we first looked at the distibutions of the ratings they gave of the checkups. The distributions across the diagonal in Figure \ref{fig:pairs} show summaries of the main rating varaibles. Ratings of the type of information recieved during GHEs include their attractiveness (AttractInfo), impressiveness (ImpressInfo), sufficiency (SuffInfo), and popularity (PopularInfo) of information. These ratings are correlated. There are also ratings of the perception of quality of periodic GHE sessions which includes the tangibles (Tangibles), assurance (Assurance), reliability (Reliability), responsibility (Respon), and empathy (Empathy) variables.

We can see that the average rating about the type of information recieved in GHEs is significantly correlated and tends to score a 3 on the 5-point scale. As well, the 


```{r q1, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}

# mod <- glm(views ~ posts + authors + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
# par(mfrow=c(2,2))
# plot(cars)
plot(1:5)
```


We were further interested in whether

## Q2. 

**What factors make a person less likely to get check-up every twelve months? Find the most important factors that could help us design our advertising, and give us some measure of how important they are.**

We aimed to determine what factors make a person less likely to get check-up every twelve months by modelling the variable RecPerExam (the time since the respondent got an unprompted checkup). RecPerExam has four levels: less12 = less than 12 months, b1224 = between 12 and 24 months, g24 = over 24 months, unknown = respondent doesn't know. We first trimmed the cases that are 'unknown' since this is not an informative response, leaving 1467 cases. Since the response variable is composed of discrete events, we used a binomial glm.

We performed best subset variable selection among all of the variables available (except the participant id) in order to exclude variables without large effects in this model. First we picked how many terms we should have in the best predictive linear model by using 10-fold cross validation with best subsets regression and plotted the mean squared error in Figure \ref{fig:cv}. We used the bestglm package to perform the cross validation. This analysis shows validation error is lowest around 8 terms.

```{r cv, echo=FALSE, message=FALSE, warning= FALSE, fig.cap="\\label{fig:cv} Cross validation error for each number of predictors"}
# http://www.science.smith.edu/~jcrouser/SDS293/labs/lab9-r.html

dat_q2 <- dat[2:48] %>% filter(RecPerExam != "unknow") %>% droplevels()
colnames(dat_q2)[11] <- "y"
# dat_q2$y <- recode(dat_q2$y, "b1224" = 0, "g24"= 1, "less12" =2,
#                    .default = levels(dat_q2$y))
dat_q2 <- dat_q2  %>% select(-y, everything())

set.seed(8)
library(bestglm)
# res.bestglm <-
#     bestglm(Xy = dat_q2,
#             family = gaussian,
#             IC = "AIC",                 # Information criteria for
#             method = "exhaustive")



# Plot the cross-validation error for each model size, highlight the min
# plot(mean_cv_errors, type='b', xlab = "Number of predictors",
#      ylab = "Mean cross validation error (percent)")
# points(min, mean_cv_errors[min][1], col = "red", cex = 2, pch = 20)
plot(1:5)
```


Next we fit the model to RecPerExam with the top XXX variables. We found the top 

## Q3. 

**Can we predict which people would be easiest to convince? That is, some people might be on the edge, and would get an exam with a little extra push; some people are very determined and would not get an exam no matter how hard you try. Using a classifier, can you find the patients who haven’t gotten an exam but are most like other patients who have? Be sure to tell us how well your classifier works, so we know whether this is reliable.**

In order to predict which people would be easiest to convince to take a GHE every 12 months, we again build a model of the time since respondent last visited a doctor for a check-up (RecPerExam). One of the four responses is 'unknown', meaning the respondent doesn't know when they last visited a doctor for a check-up when not prompted by a specific illness. However, we can try to predict for the respondents who answered 'unknown' whether they would fall into one of the other three categries  (less12 = less than 12 months, b1224 = between 12 and 24 months, g24 = over 24 months). 

We first set aside the cases for which RecPerExam is 'unknown'. Working with the remaining 1467 cases, we built a XXXXX model to predict RecPerExam. Since here we are interested in predicting RecPerExam, rather than interpretation, we decided to include all of the potential predictor variables (other than id). We randomly shuffled the rows and split the data into a training and test set. The performance of the test set as seen in Figure XXXXXXX

```{r q3, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}
# Randomize rows of top performer

# Subset data for training and testing
# N_train<- round(nrow(example)*0.75)
# train<- example[1:N_train,]
# test<- example[(N_train+1):nrow(example),]
# colnames(train)[1:2]<- c("Diagnosis", "Eigen_gene")
# colnames(test)[1:2]<- c("Diagnosis", "Eigen_gene")
# 
# # Build model and predict   
# model_IFGyel<- glm(Diagnosis ~ Eigen_gene, data = train, family = binomial())
# pred<- predict(model_IFGyel, newdata= test, type= "response")

# Convert predictions to accuracy metric
plot(1:5)

```


Next, we used our classifier to predict the status of the unknown cases. We were interested in characteristics of the patients who haven’t gotten an exam in the last 12 months, but are most like other patients who have. 

```{r classifier, fig.width=6, results='asis', fig.height=6, echo=FALSE, message=FALSE, warning= FALSE,fig.cap="\\label{fig:q1} Diagnostic plots for the fit of model 'views ~ posts + authors + offset(log(startdate)'. Multiple outliers are apparent. These outliers occurred in topics belonging to Miscellaneous sciences, Speculations, and Medicine."}
# > which(rownames(dat) == 8346,)
# [1] 7519

#temp <- dat[-7519,]
# mod <- glm(views ~ posts + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
# mod <- glm(views ~ posts + authors + offset(log(startdate)), 
#            family =quasipoisson(log), 
#            data = dat)
# par(mfrow=c(2,2))
# plot(mod)
plot(1:5)
```
## Conclusion



## Bibliography
