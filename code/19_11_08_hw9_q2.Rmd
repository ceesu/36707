---
title: "HW9"
author: "Cathy Su"
date: "8/11/2019"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
---
```{r global_options, include=FALSE}
# knitr::knit_hooks$set(plot = function(x, options)  {
#   hook_plot_tex(x, options)
# })
library(knitr)
opts_knit$set(eval.after = 'fig.cap')

# for tuning:
# http://www.louisaslett.com/Courses/Data_Mining/ST4003-Lab7-Introduction_to_Support_Vector_Machines.pdf

```

```{r setup, include=FALSE}
#http://rosmarus.refsmmat.com/datasets/datasets/hormone-diversity/ 
  
knitr::opts_chunk$set( warning=FALSE,width.cutoff=60)
set.seed(1234)

# libraries
library(stargazer)
library(tidyverse)
library(lattice)
library(dagitty)
library(reshape2)
library("ggpubr")
library(knitr)
library(ranger)
library("e1071")
```

## Q2 

### (a) 

**Use a support vector machine to classify emails as spam or ham. The e1071 package on CRAN provides a svm function that will be useful. Start by using the default parameters of the svm function and report your test-set accuracy.**

```{r}
# data
spam <- read.csv("../data/gam-spam.csv", header=FALSE)
spam$V58 <- as.factor(spam$V58)
training_rows <- sample.int(nrow(spam), round(nrow(spam) / 3))

spam.train <- spam[training_rows, ]
spam.test <- spam[-training_rows, ]

# apply log transform
cols <- names(spam.train)[1:(length(spam.train) - 1)]
for (col in cols) {
  spam.train[col] <- log(0.1 + spam.train[[col]])
  spam.test[col] <- log(0.1 + spam.test[[col]])
}
# 
fit <- svm(V58 ~ ., data = spam.train)
#summary(fit)
pred <- predict(fit, newdata = spam.test, probability = TRUE)
table(spam.test$V58, pred)
```

#### (b) 

**By default, svm uses a radial kernel, but it also supports linear, polynomial, and sigmoid kernels. Each has different tuning parameters, such as the degree of the polynomial kernel or gamma. perform cross-validation to select the best tuning parameters. Build the best classifier for each kernel, tuning over reasonable ranges of the tuning pa- rameters, and report your results. Which kernel performs best on this data? Which kernel performs worst, and why might it be the worst?**

These are the tuning parameters for each kernel:

* radial: cost, gamma
* linear: cost
* polynomial: cost, coef0, degree,  gamma
* sigmoid: cost, coef0,  gamma

I found that tuning the parameters in different function calls vs together seemed to give the same results. Therefore I tuned once, and then printed the outputs as below. The best performing kernel seems to be the 

```{r}
type <- c("linear", "polynomial","sigmoid", "radial")

params <- tune.svm(V58 ~ ., data=spam.train, 
                   cost=10^(0:4), 
                   gamma=10^(-4:-1), 
                   coef0=10^(-1:2),
                   degree=1:4)

####### polynomial
for(k in type){
  print(k)
  fit <- svm(V58 ~ ., data = spam.train,
             kernel = k,
             degree=params$best.parameter[[1]],
             cost=params$best.parameter[[4]],
             coef0=params$best.parameter[[3]], 
             gamma=params$best.parameter[[2]],
             probability = TRUE)
  #summary(fit)
  pred <- predict(fit, newdata = spam.test)
  t <- table(spam.test$V58, pred)/length(pred)
  print(kable(t))
}
```
### (c) 

**Compare the accuracyyouhaveobtainedheretotheaccuracyyouobtainedonHomework 8 while using random forests**

We see that based on the confusion matrix of each type, the 

## Q3. 

An Introduction to Statistical Learning, chapter 9, exercise 5 (pp. 369–370). 

**We have seen that we can fit an SVM with a non-linear kernel in order to perform classification using a non-linear decision boundary. We will now see that we can also obtain a non-linear decision boundary by performing logistic regression using non-linear transformations of the features.**

##### a) Generate a data set with n = 500 and p = 2, such that the obser- vations belong to two classes with a quadratic decision boundary between them. For instance, you can do this as follows:

```{r}
x1=runif(500)-0.5
x2=runif(500)-0.5
y=1*(x1^2-x2^2 > 0)
```

##### b) Plot the observations, colored according to their class labels. Your plot should display X1 on the x-axis, and X2 on the y- axis.

```{r}
plot(x1, x2, col = as.factor(y))
```


##### c) Fit a logistic regression model to the data, using X1 and X2 as predictors.

```{r}
model <- glm(y ~x1 + x2,family=binomial(link='logit'))
summary(model)
```


##### d) Apply this model to the training data in order to obtain a pre- dicted class label for each training observation. Plot the ob- servations, colored according to the predicted class labels. The decision boundary should be linear.

```{r}
pred_y <- predict.glm(model, type="response")
plot(x1, x2, col = as.factor(pred_y>0.5))
```


##### e) Now fit a logistic regression model to the data using non-linear functions of X1 and X2 as predictors (e.g. X12, X1 ×X2, log(X2), and so forth).

```{r}
model <- glm(y ~x1 + x2 +  poly(x2,2)+ poly(x1,1),family=binomial(link='logit'))
summary(model)
```

##### f) Apply this model to the training data in order to obtain a pre- dicted class label for each training observation. Plot the ob- servations, colored according to the predicted class labels. The decision boundary should be obviously non-linear. If it is not, then repeat (a)-(e) until you come up with an example in which the predicted class labels are obviously non-linear.

```{r}
pred_y <- predict.glm(model, type="response")
plot(x1, x2, col = as.factor(pred_y>0.5))
```

##### g) Fit a support vector classifier to the data with X1 and X2 as predictors. Obtain a class prediction for each training observa- tion. Plot the observations, colored according to the predicted class labels.

```{r}
fit <- svm(y ~x1 + x2, data = spam.train,kernel = "linear")
pred <- predict(fit)
plot(x1, x2, col = as.factor(pred>0.5))
```

##### h) Fit a SVM using a non-linear kernel to the data. Obtain a class prediction for each training observation. Plot the observations, colored according to the predicted class labels.

```{r}
fit <- svm(y ~x1 + x2, data = spam.train,kernel = "radial")
pred <- predict(fit)
plot(x1, x2, col = as.factor(pred>0.5))
```

##### i) Comment on your results.

* In what space is the decision boundary linear?
* If we can make logistic regression produce nonlinear decision boundaries by adding ap-
propriate covariates, why is the kernel trick in SVMs useful?**

The decision boundary for this data is linear if we square both x1 and x2, since the plot of the classes from part b is symmetric across x1=0 and x2=0.

We can get the nonlinear decision boundary through logistic regression, but it requires us to manually add the formula with new covariates and also as we see above the fit is not as good as with the SVM with radial kernel. This suggests we need to invest additional time to tune these new covariates.


## Q4

**Should we set C large or small if we want our estimated boundary to have the minimum possible variance?**

If the parameter C is large, then any wrong classification is penalized a lot. This would lead to higher variance since the classification boundary tries to eliminate every single outlier. Thus to have smaller variance we should set C to be small.

## Q5

**Unbalanced classes. Simulate a dataset with two variables, X1 and X2, and an outcome variable Y. Make the dataset have a linear decision boundary between Y = 1 and Y = 0. But put the code that simulates data into a function, and make one of the parameters of that function be the fraction of cases that should have Y = 1. This way, we can simulate what happens when the classes are imbalanced.**

```{r}
simulate <- function(fraction=0.5) {
  X <- matrix(runif(2 * N, min=0, max=10), nrow=N, ncol=2)
  Y <- ifelse((X[, 1] < 5 & X[, 2] < 5) | (X[, 1] > 5 & X[, 2] > 5), rbinom(N, 1, 0.1), rbinom(N, 1, 0.9))
  
  stopifnot(nrow(X) == length(Y)) # sanity check!
  new <- cbind(as.data.frame(X), as.dsata.frame(Y))
  new$Y <- as.factor(new$Y)
  #colnames(new)[-1] <- "Y"
  return(new)
}
```


### a)

**Set the fraction to 0.5: perfect balance. Run a logistic regression and an SVM on the data to predict Y. Compare the confusion matrices on a test set (just run your function again to get a test set!). How do the error rates compare, and do the error rates differ for points with Y = 0 vs. those with Y = 1?**


### b)

**Now repeat this analysis with fractions varying from 0.6 to 0.95. Look at the confusion matrices as the classes become less balanced.What happens to the errors for logistic regression? What kinds of errors become more common?**

### c)

**What happens to the errors for SVMs in the same case? Show a graph or table summarizing the results and comparing SVMs to logistic regression.**

### d)

**Describe, in words, why the difference you observed should exist. Give your explanation in terms of how SVMs and logistic regression find the decision boundary, and what loss functions they use.**